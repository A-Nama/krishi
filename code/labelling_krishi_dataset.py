# -*- coding: utf-8 -*-
"""labelling krishi dataset

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vZVR_vahffwVFxn982UPqxkp_ibhlPN5
"""

!pip install -U transformers

# Load model for sequence classification
from transformers import AutoModelForSequenceClassification
model = AutoModelForSequenceClassification.from_pretrained("ai4bharat/indic-bert", torch_dtype="auto")

import os
import pandas as pd
from tqdm import tqdm
import google.generativeai as genai
from google.colab import userdata

GEMINI_API_KEY = userdata.get('GOOGLE_API_KEY')

genai.configure(api_key=GEMINI_API_KEY)

LABELS = ["CROPS", "DISEASES", "AGRI_PRACTICES", "ENVIRONMENTAL_FACTORS", "LIVESTOCK"]

def classify_with_gemini(text):
    try:
        prompt = f"""
        You are a text classification system for agricultural texts.
        Categories: {LABELS}.
        Classify the following text into exactly ONE category.
        Return only the category name.

        Text: {text}
        """
        response = genai.GenerativeModel("gemini-1.5-pro").generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        print("Gemini error:", e)
        return None

def main():
    df = pd.read_csv("krishi dataset.csv")

    df["Gemini_Label"] = ""

    for i, row in tqdm(df.iterrows(), total=len(df)):
        text = str(row["Title"]) + " " + str(row["Content"])
        gemini_label = classify_with_gemini(text)
        df.at[i, "Gemini_Label"] = gemini_label

    df.to_csv("labeled_dataset.csv", index=False)
    print("✅ Labeled dataset saved as labeled_dataset.csv")

if __name__ == "__main__":
    main()

from transformers import AutoTokenizer
import torch

tokenizer = AutoTokenizer.from_pretrained("ai4bharat/indic-bert")

def classify_with_hf(text, model, tokenizer, labels):
    try:
        inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512)

        with torch.no_grad():
            outputs = model(**inputs)

        if isinstance(outputs, tuple):
            logits = outputs[0]
        else:
            logits = outputs.logits


        predicted_class_id = logits.argmax().item()


        if 0 <= predicted_class_id < len(labels):
            return labels[predicted_class_id]
        else:
            return None

    except Exception as e:
        print("Hugging Face error:", e)
        return None

try:
    df = pd.read_csv("labeled_dataset.csv")

    df["HF_Label"] = ""
    df["Conflict"] = False

    for i, row in tqdm(df.iterrows(), total=len(df)):
        text = str(row["Title"]) + " " + str(row["Content"])
        hf_label = classify_with_hf(text, model, tokenizer, LABELS)
        df.at[i, "HF_Label"] = hf_label

        if row["Gemini_Label"] != hf_label:
            df.at[i, "Conflict"] = True

    df.to_csv("labeled_dataset.csv", index=False)
    print("✅ Added Hugging Face labels and conflict check to the dataset.")
    print("Updated dataset saved as labeled_dataset.csv")

except NameError:
    print("Error: DataFrame 'df' not found. Please ensure the dataset is loaded.")

import pandas as pd

try:
    df = pd.read_csv("labeled_dataset.csv")

    df['label'] = None

    df.loc[df['Conflict'] == False, 'label'] = df['Gemini_Label']

    df.to_csv("labeled_dataset.csv", index=False)

    print("✅ Added 'label' column to labeled_dataset.csv. Conflicting entries are left blank for manual review.")
    display(df.head())

except FileNotFoundError:
    print("Error: labeled_dataset.csv not found. Please ensure the previous steps were completed successfully.")
except KeyError as e:
    print(f"Error: Required column not found in labeled_dataset.csv: {e}. Please check the column names.")
except Exception as e:
    print(f"An unexpected error occurred: {e}")